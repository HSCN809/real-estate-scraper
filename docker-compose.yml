services:
  # PostgreSQL Database
  db:
    image: postgres:16-alpine
    container_name: real-estate-db
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - real-estate-network

  # Redis - Message Broker for Celery
  redis:
    image: redis:7-alpine
    container_name: real-estate-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - real-estate-network

  # Backend API - FastAPI (No scraping here, just API)
  api:
    build:
      context: ./Backend
      dockerfile: Dockerfile
    container_name: real-estate-api
    ports:
      - "${FASTAPI_PORT:-8000}:8000"
    volumes:
      # Log dosyalari
      - ./Backend/logs:/app/logs
      # Export ciktilari
      - ./Backend/outputs:/app/outputs
    environment:
      - FASTAPI_HOST=${FASTAPI_HOST}
      - FASTAPI_PORT=${FASTAPI_PORT}
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - CORS_ORIGINS=${CORS_ORIGINS}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - JWT_ALGORITHM=${JWT_ALGORITHM}
      - ACCESS_TOKEN_EXPIRE_DAYS=${ACCESS_TOKEN_EXPIRE_DAYS}
      - ENVIRONMENT=${ENVIRONMENT}
      - LOG_LEVEL=${LOG_LEVEL}
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    networks:
      - real-estate-network

  # Celery Worker - Scraping tasks run here
  worker:
    build:
      context: ./Backend
      dockerfile: Dockerfile.worker
    container_name: real-estate-worker
    init: true  # Zombie process'leri temizler
    shm_size: '2gb'  # Chrome i√ßin shared memory
    volumes:
      # Log dosyalari (worker loglari)
      - ./Backend/logs:/app/logs
      # Export ciktilari
      - ./Backend/outputs:/app/outputs
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - CHROME_HEADLESS=${CHROME_HEADLESS}
      - LOG_LEVEL=${LOG_LEVEL}
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "celery -A celery_app inspect ping --timeout 5 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    networks:
      - real-estate-network

  # Flower - Celery Monitoring UI
  flower:
    image: mher/flower:2.0
    container_name: real-estate-flower
    ports:
      - "5555:5555"
    environment:
      - CELERY_BROKER_URL=${REDIS_URL}
      - FLOWER_PORT=5555
      - FLOWER_BASIC_AUTH=${FLOWER_BASIC_AUTH}
    depends_on:
      redis:
        condition: service_healthy
      worker:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - real-estate-network

  # Frontend - Next.js (Development Mode with Hot Reload)
  frontend:
    image: node:20-alpine
    container_name: real-estate-frontend
    working_dir: /app
    ports:
      - "3000:3000"
    volumes:
      # Source code mount for hot reload
      - ./Frontend:/app
      # Anonymous volume for node_modules (prevents overwrite)
      - /app/node_modules
      - /app/.next
    environment:
      - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL}
      - NODE_ENV=development
      - WATCHPACK_POLLING=true
    command: sh -c "npm install && npm run dev"
    depends_on:
      api:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - real-estate-network

networks:
  real-estate-network:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
