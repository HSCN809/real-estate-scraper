services:
  # PostgreSQL Database
  db:
    image: postgres:16-alpine
    container_name: real-estate-db
    environment:
      POSTGRES_USER: scraper
      POSTGRES_PASSWORD: scraper_password
      POSTGRES_DB: real_estate
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U scraper -d real_estate"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - real-estate-network

  # Redis - Message Broker for Celery
  redis:
    image: redis:7-alpine
    container_name: real-estate-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - real-estate-network

  # Backend API - FastAPI (No scraping here, just API)
  api:
    build:
      context: ./Backend
      dockerfile: Dockerfile
    container_name: real-estate-api
    ports:
      - "8000:8000"
    volumes:
      # Log dosyalari
      - ./Backend/logs:/app/logs
      # Export ciktilari
      - ./Backend/outputs:/app/outputs
    environment:
      - FASTAPI_HOST=0.0.0.0
      - FASTAPI_PORT=8000
      - DATABASE_URL=postgresql://scraper:scraper_password@db:5432/real_estate
      - REDIS_URL=redis://redis:6379/0
      - LOG_LEVEL=INFO
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    networks:
      - real-estate-network

  # Celery Worker - Scraping tasks run here
  worker:
    build:
      context: ./Backend
      dockerfile: Dockerfile.worker
    container_name: real-estate-worker
    init: true  # Zombie process'leri temizler
    shm_size: '2gb'  # Chrome i√ßin shared memory
    volumes:
      # Log dosyalari (worker loglari)
      - ./Backend/logs:/app/logs
      # Export ciktilari
      - ./Backend/outputs:/app/outputs
    environment:
      - DATABASE_URL=postgresql://scraper:scraper_password@db:5432/real_estate
      - REDIS_URL=redis://redis:6379/0
      - CHROME_HEADLESS=false
      - LOG_LEVEL=INFO
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "celery -A celery_app inspect ping --timeout 5 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    networks:
      - real-estate-network

  # Flower - Celery Monitoring UI
  flower:
    image: mher/flower:2.0
    container_name: real-estate-flower
    ports:
      - "5555:5555"
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - FLOWER_PORT=5555
      - FLOWER_BASIC_AUTH=admin:admin123
    depends_on:
      redis:
        condition: service_healthy
      worker:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - real-estate-network

  # Frontend - Next.js (Development Mode with Hot Reload)
  frontend:
    image: node:20-alpine
    container_name: real-estate-frontend
    working_dir: /app
    ports:
      - "3000:3000"
    volumes:
      # Source code mount for hot reload
      - ./Frontend:/app
      # Anonymous volume for node_modules (prevents overwrite)
      - /app/node_modules
      - /app/.next
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8000/api/v1
      - NODE_ENV=development
      - WATCHPACK_POLLING=true
    command: sh -c "npm install && npm run dev"
    depends_on:
      api:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - real-estate-network

networks:
  real-estate-network:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
